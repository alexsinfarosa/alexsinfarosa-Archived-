<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="author" content="Alex Sinfarosa"><meta name="description" content="Personal Blog/Website"><title>Alex Sinfarosa</title><link rel="icon" href="/"><link rel="canonical" href="http://.alexsinfarosa.com/"><link rel="alternate" href="/atom.xml" title="Alex Sinfarosa"><link rel="stylesheet" href="/fonts/iconfont/iconfont.css"><link rel="stylesheet" href="/css/style.css"><script type="text/javascript"><!-- hexo-inject:begin --><!-- hexo-inject:end -->var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?Your baidu Analytics ID";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script type="text/javascript">(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-84813198-1', 'auto');
ga('send', 'pageview');</script><!-- hexo-inject:begin --><!-- hexo-inject:end --></head><body><div id="main"><header><a href="/." class="logo">Alex Sinfarosa</a><ul class="nav"><li class="nav-link"><a href="/" class="active">Accueil</a></li><li class="nav-link"><a href="/archives/" target="_self">Archives</a></li><li class="nav-link"><a href="/tags/" target="_self">Tags</a></li><li class="nav-link"><a href="/about/" target="_self">À propos</a></li></ul></header><section id="container"><ul class="home"><li class="post-item"><article class="post"><h2 class="post-title"><a href="/2016/06/16/Logistic-Regression-Modeling-of-Real-Estate-Properties/" class="post-link">Logistic Regression Modeling of Real Estate Properties</a></h2><span class="post-time">Jun 16, 2016</span><div class="post-content"><p>I was recently tasked with discovering some additional information from a set of housing data in the upstate New York region that could help elucidate why some properties sell over others. Given two <code>csv</code> files with data from active and sold properties, I immediately thought how cool it would be to build a predictive model using logistic regression! I built the whole thing in R, too, which gave me more experience with the software, and surprised me in its simplicity and power. I was limited by my dataset, as it was not as large as I would have hoped for, but nevertheless, I got right down to work.</p></div><a href="/2016/06/16/Logistic-Regression-Modeling-of-Real-Estate-Properties/" class="read-more">Lire la suite..</a></article></li><li class="post-item"><article class="post"><h2 class="post-title"><a href="/2016/05/08/Spearman-and-Pearson-Correlation/" class="post-link">Spearman and Pearson Correlation</a></h2><span class="post-time">May 8, 2016</span><div class="post-content"><p>In the following notebook we will determine whether three sets of numbers are correlated.</p>
<!-- hexo-inject:begin --><!-- hexo-inject:end --><p>We will use one more time the thirty politics articles (those labelled p0.txt through p29.txt) contained in the<br><a href="https://github.com/alexsinfarosa/Baby-Machine-Learning/tree/master/data">data</a> folder.</p>
<p>Each of the article webpages has three icons labelling counts for a) Facebook likes, b) Tweets, and c) Comments.</p></div><a href="/2016/05/08/Spearman-and-Pearson-Correlation/" class="read-more">Lire la suite..</a></article></li><li class="post-item"><article class="post"><h2 class="post-title"><a href="/2016/05/04/Logistic-Regression/" class="post-link">Logistic Regression</a></h2><span class="post-time">May 4, 2016</span><div class="post-content"><p>This time we are going to look at logistic regression. The data were obtained by the<br><a href="https://en.wikipedia.org/wiki/Space_Shuttle_Challenger_disaster">Space Shuttle Challenger disaster</a> O-ring data failure data (from 1986):</p></div><a href="/2016/05/04/Logistic-Regression/" class="read-more">Lire la suite..</a></article></li><li class="post-item"><article class="post"><h2 class="post-title"><a href="/2016/04/29/Recommendation-System/" class="post-link">Recommendation System</a></h2><span class="post-time">Apr 29, 2016</span><div class="post-content"><p>In the following notebook we will attempt to determine the recommendations for some specified users. In other words we will pick some random users and get movie recommendations for them.</p></div><a href="/2016/04/29/Recommendation-System/" class="read-more">Lire la suite..</a></article></li><li class="post-item"><article class="post"><h2 class="post-title"><a href="/2016/04/23/Simple-Spelling-Corrector/" class="post-link">Simple Spelling Corrector</a></h2><span class="post-time">Apr 23, 2016</span><div class="post-content"><p>In “How to Write a Spelling Corrector” <a href="http://norvig.com/spell-correct.html">http://norvig.com/spell-correct.html</a>, Norvig describes training his algorithm on about a million words taken from several public domain books. Various precompiled word frequency lists are also available on the web, for example for all of the Project Gutenberg texts up to Apr 2006 at <a href="http://en.wiktionary.org/wiki/Wiktionary:Frequency_lists#Project_Gutenberg">http://en.wiktionary.org/wiki/Wiktionary:Frequency_lists#Project_Gutenberg</a> .</p></div><a href="/2016/04/23/Simple-Spelling-Corrector/" class="read-more">Lire la suite..</a></article></li><li class="post-item"><article class="post"><h2 class="post-title"><a href="/2016/03/16/Zipf-s-Law/" class="post-link">Zipf's Law</a></h2><span class="post-time">Mar 16, 2016</span><div class="post-content"><p>The linguist George Kingsley Zipf, who theorised that given a large body of language (that is, a long book — or every word uttered by Plus employees during the day), the frequency of each word is close to inversely proportional to its rank in the frequency table.</p>
<p>In this guide we’ll write some code to look at some word distributions and power laws.</p></div><a href="/2016/03/16/Zipf-s-Law/" class="read-more">Lire la suite..</a></article></li><li class="post-item"><article class="post"><h2 class="post-title"><a href="/2016/02/21/Naive-Bayes-text-classifier/" class="post-link">Naive Bayes Text Classifier</a></h2><span class="post-time">Feb 21, 2016</span><div class="post-content"><p>The following code will attempt to illustrate how to apply the “Naive Bayes” methodology to construct a simple text classifier.</p></div><a href="/2016/02/21/Naive-Bayes-text-classifier/" class="read-more">Lire la suite..</a></article></li></ul><div class="paginator"></div></section><footer><div class="social"><a href="https://twitter.com/alex_sinfarosa" title="twitter" class="iconfont icon-twitter"></a><a href="https://github.com/alexsinfarosa" title="github" class="iconfont icon-github"></a></div><div class="copyright"><p class="power">Powered by <a href="https://hexo.io/">Hexo</a> and Theme by <a href="https://github.com/ahonn/hexo-theme-even"> Even</a></p><p class="since">&copy;2016<span class="heart"><i class="iconfont icon-heart"></i></span><span class="author">Alex Sinfarosa</span></p></div><label id="back2top"><i class="iconfont icon-up"></i></label></footer></div><script src="/js/zepto.min.js"></script><script src="/js/theme.js"></script><!-- hexo-inject:begin --><!-- hexo-inject:end --></body></html>