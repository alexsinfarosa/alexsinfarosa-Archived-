<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="author" content="Alex Sinfarosa"><meta name="description" content="Arandomgraphisobtainedbystartingwithasetofnisolatedverticesandaddingsuccessiveedgesbetweenthematrandom.TheErdős–Rényi"><meta name="keywords" content="Machine Learning,Python,Random Graphs"><title>Random Graphs · Alex Sinfarosa</title><link rel="icon" href="/"><link rel="canonical" href="http://.alexsinfarosa.com/2016/03/30/Random-Graphs/"><link rel="alternate" href="/atom.xml" title="Alex Sinfarosa"><link rel="stylesheet" href="/fonts/iconfont/iconfont.css"><link rel="stylesheet" href="/css/style.css"><script type="text/javascript"><!-- hexo-inject:begin --><!-- hexo-inject:end -->var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?Your baidu Analytics ID";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script type="text/javascript">(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-84813198-1', 'auto');
ga('send', 'pageview');</script><!-- hexo-inject:begin --><!-- hexo-inject:end --></head><body><div id="main"><header><a href="/." class="logo">Alex Sinfarosa</a><ul class="nav"><li class="nav-link"><a href="/" target="_self">Home</a></li><li class="nav-link"><a href="/archives/" target="_self">Archives</a></li><li class="nav-link"><a href="/tags/" target="_self">Tags</a></li><li class="nav-link"><a href="/about/" target="_self">About</a></li></ul></header><section id="container"><article class="post"><h1 class="post-title">Random Graphs</h1><span class="post-time">Mar 30, 2016</span><div id="sidebar" class="post-sidebar"><h3 class="heading">Contents</h3><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#Basic-principles"><span class="toc-text">Basic principles</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Let’s-start"><span class="toc-text">Let’s start</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Plot-histogram-of-the-degree-distribution"><span class="toc-text">Plot histogram of the degree distribution</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Now-let’s-test-the-“your-friends-have-more-friends-than-you-do”-idea"><span class="toc-text">Now, let’s test the “your friends have more friends than you do” idea</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Finally-let’s-try-to-construct-a-more-realistic-social-network"><span class="toc-text">Finally, let’s try to construct a more realistic social network</span></a></li></ol></div><div class="post-content"><p>A <a href="https://en.wikipedia.org/wiki/Random_graph" target="_blank" rel="external">random graph</a> is obtained by starting with a set of n isolated vertices and adding successive edges between them at random. The Erdős–Rényi model denoted G(n,M), assigns equal probability to all graphs with exactly M edges. With 0 ≤ M ≤ N, G(n,M) has ${\tbinom {N}{M}}$ elements and every element occurs with probability $1/{\tbinom {N}{M}}$.</p>
<!-- hexo-inject:begin --><!-- hexo-inject:end --><a id="more"></a>
<p>Let’s start by importing a few libraries</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> random</div><div class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter,defaultdict</div><div class="line">%matplotlib inline</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div></pre></td></tr></table></figure>
<h3 id="Basic-principles"><a href="#Basic-principles" class="headerlink" title="Basic principles"></a>Basic principles</h3><p>The <code>random.sample()</code> function has the feature that it will draw sets of distinct numbers, for example, to draw two numbers in the range from 0 to 99, where the two numbers are always different we can do the following:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">N=<span class="number">100</span></div><div class="line">random.sample(range(N),<span class="number">2</span>)</div></pre></td></tr></table></figure>
<pre><code>[83, 54]
</code></pre><p>We will label the vertices of the graph by integers, and this permits specifying random edges. Suppose we want a random graph with <code>N</code> vertices and an average of <code>z</code> neighbors per vertex, how many total edges should we add? Let <code>L</code> be the number of edges. Each edge contributes 1 to the degree of each of the vertices to which it’s incident, so that means <code>2*L=N*z</code>. That means we need to add <code>L=N*z/2.</code> edges in order to have an average degree of <code>z</code>.  Let’s create a graph with <code>N=100000</code> vertices and average degree <code>z=5</code>. Let <code>E</code> be the set of edges for the graph,</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">z=<span class="number">5</span></div><div class="line">N=<span class="number">100000</span></div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">E=set()</div><div class="line">L=N*z/<span class="number">2.</span></div><div class="line"><span class="keyword">while</span>(len(E)&lt;L): E.add(tuple(random.sample(range(N),<span class="number">2</span>)))</div></pre></td></tr></table></figure>
<p>The above code creates a set of exactly <code>L</code> random edges drawn from the total possible ${N\choose2}=N(N-1)/2$. In this case the probability of an edge is given by $p=L/{N\choose2}$. (Note that while <code>random.sample()</code> always draws distinct vertices to make an edge, it might draw the same edge more than once if <code>p</code> is large enough. But <code>E</code> is defined as a <code>set()</code>, so edges are only counted once and that won’t affect anything. The <code>tuple()</code> in the above converts a two element list, e.g., [23,72], to a tuple (23,72), which for our purposes is an object that can serve as an element of a set.</p>
<h3 id="Let’s-start"><a href="#Let’s-start" class="headerlink" title="Let’s start"></a>Let’s start</h3><p>We will use the graph created above and calculate the mean and standard deviation of the degree distribution of the vertices. To do this, it is useful to make a list of the vertices in the above edge set, counted with multiplicity:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">degree=Counter([n <span class="keyword">for</span> l <span class="keyword">in</span> E <span class="keyword">for</span> n <span class="keyword">in</span> l])</div></pre></td></tr></table></figure>
<p>The <code>degree</code> dictionary gives the number of times each vertex occurs in the original edge set E, i.e., its degree.</p>
<p>We also need to take care of the vertices with degree zero</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">zeros=N-len(degree)</div><div class="line">degree.update(&#123;k:<span class="number">0</span> <span class="keyword">for</span> k <span class="keyword">in</span> range(N) <span class="keyword">if</span> k <span class="keyword">not</span> <span class="keyword">in</span> degree&#125;)</div><div class="line">zeros</div></pre></td></tr></table></figure>
<pre><code>694
</code></pre><p>Calling <code>np.mean()</code> and <code>np.std()</code> on the <code>.values()</code> of the <code>degree</code> dictionary will then give the mean and standard deviation of the degree distribution.<br>We will also check that the mean is close to the desired <code>z</code>, and that the standard deviation is what one would expect for a Poisson distribution of degrees.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">print(np.sum(list(degree.values())))</div><div class="line">print(np.mean(list(degree.values())),<span class="string">'is close to'</span>,z)</div><div class="line">print(np.std(list(degree.values())),<span class="string">'is close to'</span>,np.sqrt(z))</div></pre></td></tr></table></figure>
<pre><code>500000
5.0 is close to 5
2.23867818143 is close to 2.2360679775
</code></pre><h3 id="Plot-histogram-of-the-degree-distribution"><a href="#Plot-histogram-of-the-degree-distribution" class="headerlink" title="Plot histogram of the degree distribution"></a>Plot histogram of the degree distribution</h3><p>First let’s define the function</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> scipy.misc <span class="keyword">import</span> factorial</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">poisson</span><span class="params">(m,z=<span class="number">1</span>)</span>:</span> <span class="keyword">return</span> np.exp(-z)*z**m/factorial(m)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">plt.hist(list(degree.values()),bins=range(<span class="number">20</span>),align=<span class="string">'left'</span>,alpha=<span class="number">0.3</span>, rwidth = <span class="number">0.9</span>, label=<span class="string">'data'</span>)</div><div class="line">plt.plot(N*poisson(np.arange(<span class="number">20</span>),np.mean(list(degree.values()))),<span class="string">'ro-'</span>,linewidth=<span class="number">1.5</span>, label=<span class="string">'Poisson'</span>)</div><div class="line"><span class="comment"># axes and labels</span></div><div class="line">plt.title(<span class="string">'Degree distribution'</span>,fontsize=<span class="number">12</span>)</div><div class="line">plt.xlabel(<span class="string">'Degree'</span>,fontsize=<span class="number">11</span>)</div><div class="line">plt.xlim(<span class="number">-.5</span>,<span class="number">15</span>)</div><div class="line">plt.ylabel(<span class="string">'node count'</span>,fontsize=<span class="number">11</span>)</div><div class="line">plt.legend();</div></pre></td></tr></table></figure>
<p><img src="output_21_0.png" alt="png"></p>
<h3 id="Now-let’s-test-the-“your-friends-have-more-friends-than-you-do”-idea"><a href="#Now-let’s-test-the-“your-friends-have-more-friends-than-you-do”-idea" class="headerlink" title="Now, let’s test the “your friends have more friends than you do” idea"></a>Now, let’s test the “your friends have more friends than you do” idea</h3><p>We will use <code>randint(N,size=100)</code> to pick 100 vertices at random, and calculate the average degree of those vertices. That average should again be close to z.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">np.mean([degree[j] <span class="keyword">for</span> j <span class="keyword">in</span> np.random.randint(N,size=<span class="number">100</span>)])</div></pre></td></tr></table></figure>
<pre><code>4.96
</code></pre><p>Now instead we pick 100 vertices at random, and for each of those vertices we pick one of its neighbors at random, and calculate the average degree of those 100 neighbors. To do this efficiently, it will be useful to create a new dictionary <code>neighbors[]</code>, which has vertices as keys and for each vertex a list of its neighbors as value.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">neighbors=defaultdict(list)</div><div class="line"><span class="keyword">for</span> j1,j2 <span class="keyword">in</span> E:</div><div class="line">    neighbors[j1].append(j2)</div><div class="line">    neighbors[j2].append(j1)</div></pre></td></tr></table></figure>
<p>Then <code>random.choice(neighbors[8])</code> will choose one of those five neighbors at random. Using these as keys to the <code>degree[]</code> counter permits finding the mean of the degrees of the 100 random friends of the 100 random vertices chosen.<br>We will check wheter that mean is greater than the mean of part 1, and if so if it is greater by the expected amount (where for Poisson the variance is equal to the mean so mean + var/mean = mean + 1):</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">random_neighbors=[random.choice(neighbors[j]) <span class="keyword">for</span> j <span class="keyword">in</span> np.random.randint(N,size=<span class="number">100</span>)]</div><div class="line">expected=np.mean(list(degree.values())) + np.var(list(degree.values()))/np.mean(list(degree.values()))</div><div class="line">print(np.mean(list([degree[j] <span class="keyword">for</span> j <span class="keyword">in</span> random_neighbors])),<span class="string">'is larger than'</span>,np.mean(list(degree.values())),\</div><div class="line">      <span class="string">'and close to'</span>,expected)</div></pre></td></tr></table></figure>
<pre><code>5.82 is larger than 5.0 and close to 6.002336
</code></pre><h3 id="Finally-let’s-try-to-construct-a-more-realistic-social-network"><a href="#Finally-let’s-try-to-construct-a-more-realistic-social-network" class="headerlink" title="Finally, let’s try to construct a more realistic social network"></a>Finally, let’s try to construct a more realistic social network</h3><p>Social graphs are characterized by the “triadic closure” property. For each vertex, we can construct a list of distinct pairs of friends:</p>
<pre><code>friend_pairs= [(f1,f2) for f1 in neighbors[j] for f2 in neighbors[j] if f1&lt;f2]
</code></pre><p>Some of these <code>(f1,f2)</code> edges will already be in <code>F</code>, but only with small probability <code>p</code>.<br>The <em>clustering coefficient</em> for vertex <code>j</code> is given by the ratio of closed triangles over total number of possible closed triangles. For the above list of friend pairs, that’s just the number of current edges <code>(f1,f2)</code> in <code>F</code> divided by the length of the list.</p>
<p>We are going to determine the average clustering coefficient of the graph by summing the clustering coefficients for all the vertices and dividing by the number of vertices.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">clust_coeff=<span class="number">0</span></div><div class="line"><span class="keyword">for</span> j <span class="keyword">in</span> sorted(neighbors):</div><div class="line">    friend_pairs= [(i1,i2) <span class="keyword">for</span> i1 <span class="keyword">in</span> neighbors[j] <span class="keyword">for</span> i2 <span class="keyword">in</span> neighbors[j] <span class="keyword">if</span> i1&lt;i2]</div><div class="line">    <span class="keyword">if</span> len(friend_pairs) == <span class="number">0</span>: <span class="keyword">continue</span></div><div class="line">    clust_coeff += sum([i1 <span class="keyword">in</span> neighbors[i2] <span class="keyword">for</span> i1,i2 <span class="keyword">in</span> friend_pairs])/float(len(friend_pairs))</div><div class="line">print(<span class="string">'average clustering coefficient'</span>,clust_coeff/float(len(neighbors)))</div></pre></td></tr></table></figure>
<pre><code>average clustering coefficient 3.994264764006774e-05
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">F=E.copy()</div><div class="line"></div><div class="line"><span class="keyword">for</span> j <span class="keyword">in</span> sorted(neighbors):</div><div class="line">    friend_pairs= [(i1,i2) <span class="keyword">for</span> i1 <span class="keyword">in</span> neighbors[j] <span class="keyword">for</span> i2 <span class="keyword">in</span> neighbors[j] <span class="keyword">if</span> i1&lt;i2]</div><div class="line">    <span class="keyword">for</span> edge <span class="keyword">in</span> friend_pairs:</div><div class="line">        <span class="keyword">if</span> np.random.rand()&gt;<span class="number">.5</span>: F.add(edge)</div></pre></td></tr></table></figure>
<p>Now, the number of edges in the edge set F should be more than three times as many.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">len(E),len(F)</div></pre></td></tr></table></figure>
<pre><code>(250000, 876178)
</code></pre><p>We can calculate the mean and standard deviation of the degree distribution of F.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">fdegree=Counter([n <span class="keyword">for</span> l <span class="keyword">in</span> F <span class="keyword">for</span> n <span class="keyword">in</span> l])</div><div class="line">avg=np.mean(list(fdegree.values())+zeros*[<span class="number">0</span>])</div><div class="line">stdev=np.std(list(fdegree.values())+zeros*[<span class="number">0</span>])</div><div class="line">print(<span class="string">'mean ='</span>,avg)</div><div class="line">print(<span class="string">'standard deviation ='</span>,stdev)</div></pre></td></tr></table></figure>
<pre><code>mean = 17.52356
standard deviation = 8.59866181021
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">fneighbors=defaultdict(list)</div><div class="line"><span class="keyword">for</span> j1,j2 <span class="keyword">in</span> F:</div><div class="line">    fneighbors[j1].append(j2)</div><div class="line">    fneighbors[j2].append(j1)</div></pre></td></tr></table></figure>
<p>The average clustering coefficient is now:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">clust_coeff=<span class="number">0</span></div><div class="line"><span class="keyword">for</span> j <span class="keyword">in</span> sorted(fneighbors):</div><div class="line">    friend_pairs= [(i1,i2) <span class="keyword">for</span> i1 <span class="keyword">in</span> fneighbors[j] <span class="keyword">for</span> i2 <span class="keyword">in</span> fneighbors[j] <span class="keyword">if</span> i1&lt;i2]</div><div class="line">    <span class="keyword">if</span> len(friend_pairs) == <span class="number">0</span>: <span class="keyword">continue</span></div><div class="line">    clust_coeff += sum([i1 <span class="keyword">in</span> fneighbors[i2] <span class="keyword">for</span> i1,i2 <span class="keyword">in</span> friend_pairs])/float(len(friend_pairs))</div><div class="line">print(<span class="string">'average clustering coefficient'</span>,clust_coeff/float(len(neighbors)))</div></pre></td></tr></table></figure>
<pre><code>average clustering coefficient 0.21727725319741498
</code></pre><p>The clustering coefficient is much larger than the one found above.</p>
</div></article><div class="tags"><a href="/tags/Machine-Learning/">Machine Learning</a><a href="/tags/Python/">Python</a><a href="/tags/Random-Graphs/">Random Graphs</a></div><div class="paginator"><a href="/2016/04/13/Simple-Spelling-Corrector/" class="prev"><i class="iconfont icon-left"></i><span> Prev</span></a><a href="/2016/03/16/Zipf-s-Law/" class="next"><span>Next</span><i class="iconfont icon-right"></i></a></div><section id="comments"><div id="disqus_thread"></div></section><script type="text/javascript">var disqus_config = function () {
    this.page.url = 'http://.alexsinfarosa.com/2016/03/30/Random-Graphs/';
    this.page.identifier = '2016/03/30/Random-Graphs/';
    this.page.title = 'Random Graphs';
};
(function() {
var d = document, s = d.createElement('script');

s.src = '//alexsinfarosa-com.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();</script></section><footer><div class="copyright"><p class="power">Powered by <a href="https://hexo.io/">Hexo</a> and Theme by <a href="https://github.com/ahonn/hexo-theme-even"> Even</a></p><p class="since">&copy;2016<span class="heart"><i class="iconfont icon-heart"></i></span><span class="author">Alex Sinfarosa</span></p></div><label id="back2top"><i class="iconfont icon-up"></i></label></footer></div><script src="/js/zepto.min.js"></script><script src="/js/theme.js"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end --></body></html>