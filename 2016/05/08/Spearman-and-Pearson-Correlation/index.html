<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="author" content="Alex Sinfarosa"><meta name="description" content="Inthefollowingnotebookwewilldeterminewhetherthreesetsofnumbersarecorrelated.Wewilluseonemoretimethethirtypoliticsarti"><meta name="keywords" content="Machine Learning,Python,Spearman Correlation,Pearson Correlation,Linear Regression"><title>Spearman and Pearson Correlation · Alex Sinfarosa</title><link rel="icon" href="/"><link rel="canonical" href="http://.alexsinfarosa.com/2016/05/08/Spearman-and-Pearson-Correlation/"><link rel="alternate" href="/atom.xml" title="Alex Sinfarosa"><link rel="stylesheet" href="/fonts/iconfont/iconfont.css"><link rel="stylesheet" href="/css/style.css"><script type="text/javascript"><!-- hexo-inject:begin --><!-- hexo-inject:end -->var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?Your baidu Analytics ID";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script type="text/javascript">(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-84813198-1', 'auto');
ga('send', 'pageview');</script><!-- hexo-inject:begin --><!-- hexo-inject:end --></head><body><div id="main"><header><a href="/." class="logo">Alex Sinfarosa</a><ul class="nav"><li class="nav-link"><a href="/" target="_self">Accueil</a></li><li class="nav-link"><a href="/archives/" target="_self">Archives</a></li><li class="nav-link"><a href="/tags/" target="_self">Tags</a></li><li class="nav-link"><a href="/about/" target="_self">À propos</a></li></ul></header><section id="container"><article class="post"><h1 class="post-title">Spearman and Pearson Correlation</h1><span class="post-time">May 8, 2016</span><div id="sidebar" class="post-sidebar"><h3 class="heading">Sommaire</h3><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#The-data"><span class="toc-text">The data</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Importing-Libraries"><span class="toc-text">Importing Libraries</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Determine-correlation-between-the-sets"><span class="toc-text">Determine correlation between the sets</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Find-most-correlated-words"><span class="toc-text">Find most correlated words</span></a></li></ol></div><div class="post-content"><p>In the following notebook we will determine whether three sets of numbers are correlated.</p>
<!-- hexo-inject:begin --><!-- hexo-inject:end --><p>We will use one more time the thirty politics articles (those labelled p0.txt through p29.txt) contained in the<br><a href="https://github.com/alexsinfarosa/Baby-Machine-Learning/tree/master/data" target="_blank" rel="external">data</a> folder.</p>
<p>Each of the article webpages has three icons labelling counts for a) Facebook likes, b) Tweets, and c) Comments.</p>
<a id="more"></a>
<h3 id="The-data"><a href="#The-data" class="headerlink" title="The data"></a>The data</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">fblikes = [<span class="number">101</span>, <span class="number">54</span>, <span class="number">171</span>, <span class="number">5900</span>, <span class="number">2400</span>, <span class="number">385</span>, <span class="number">14400</span>, <span class="number">356</span>, <span class="number">553</span>, <span class="number">146</span>, <span class="number">14400</span>, <span class="number">359</span>, <span class="number">134</span>, <span class="number">40</span>, <span class="number">3400</span>,</div><div class="line">           <span class="number">933</span>, <span class="number">16800</span>, <span class="number">4400</span>, <span class="number">303</span>, <span class="number">7000</span>, <span class="number">1100</span>, <span class="number">427</span>, <span class="number">214</span>, <span class="number">94</span>, <span class="number">1300</span>, <span class="number">1800</span>, <span class="number">882</span>, <span class="number">90</span>, <span class="number">2800</span>, <span class="number">2400</span>]</div><div class="line">tweets = [<span class="number">48</span>, <span class="number">29</span>, <span class="number">67</span>, <span class="number">950</span>, <span class="number">201</span>, <span class="number">103</span>, <span class="number">757</span>, <span class="number">108</span>, <span class="number">130</span>, <span class="number">41</span>, <span class="number">901</span>, <span class="number">80</span>, <span class="number">63</span>, <span class="number">43</span>, <span class="number">205</span>,</div><div class="line">          <span class="number">95</span>, <span class="number">432</span>, <span class="number">260</span>, <span class="number">127</span>, <span class="number">326</span>, <span class="number">75</span>, <span class="number">108</span>, <span class="number">60</span>, <span class="number">52</span>, <span class="number">147</span>, <span class="number">228</span>, <span class="number">75</span>, <span class="number">51</span>, <span class="number">291</span>, <span class="number">761</span>]</div><div class="line">comments = [<span class="number">274</span>, <span class="number">290</span>, <span class="number">98</span>, <span class="number">546</span>, <span class="number">111</span>, <span class="number">185</span>, <span class="number">1900</span>, <span class="number">108</span>, <span class="number">563</span>, <span class="number">158</span>, <span class="number">934</span>, <span class="number">1100</span>, <span class="number">885</span>, <span class="number">122</span>, <span class="number">166</span>,</div><div class="line">           <span class="number">332</span>, <span class="number">1700</span>, <span class="number">1800</span>, <span class="number">213</span>, <span class="number">2300</span>, <span class="number">3000</span>, <span class="number">11</span>, <span class="number">63</span>, <span class="number">107</span>, <span class="number">142</span>, <span class="number">466</span>, <span class="number">327</span>, <span class="number">49</span>, <span class="number">2000</span>, <span class="number">194</span>]</div></pre></td></tr></table></figure>
<h3 id="Importing-Libraries"><a href="#Importing-Libraries" class="headerlink" title="Importing Libraries"></a>Importing Libraries</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> pearsonr,spearmanr,linregress</div><div class="line">%matplotlib inline</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div></pre></td></tr></table></figure>
<h3 id="Determine-correlation-between-the-sets"><a href="#Determine-correlation-between-the-sets" class="headerlink" title="Determine correlation between the sets"></a>Determine correlation between the sets</h3><p>For the three pairwise possibilities, we will check using <code>pearsonr()</code> and <code>spearmanr()</code> (both from <code>scipy.stats</code>) whether they are positively or negatively correlated with less than <code>p=.05</code> (meaning that there’s less than a 5% probability that the observed correlation would be seen in randomized data).</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> pair,c1,c2 <span class="keyword">in</span> (<span class="string">'fb/tw'</span>,fblikes,tweets),(<span class="string">'fb/co'</span>,fblikes,comments),(<span class="string">'tw/co'</span>,tweets,comments):</div><div class="line">    r,p=pearsonr(c1,c2)</div><div class="line">    print(pair,<span class="string">'Pearson  r=&#123;:.2f&#125;, p=&#123;:.6f&#125;'</span>.format(r,p))</div><div class="line">    r,p=spearmanr(c1,c2)</div><div class="line">    print(<span class="string">'      Spearman r=&#123;:.2f&#125;, p=&#123;:.6f&#125;'</span>.format(r,p))</div></pre></td></tr></table></figure>
<pre><code>fb/tw Pearson  r=0.74, p=0.000002
      Spearman r=0.93, p=0.000000
fb/co Pearson  r=0.50, p=0.004842
      Spearman r=0.58, p=0.000735
tw/co Pearson  r=0.27, p=0.142944
      Spearman r=0.47, p=0.008601
</code></pre><p>The results above show that they are all positively correlated (with the Spearman correlation between facebook likes and tweets particularly strong with <code>r=.93</code>). Only the Pearson <code>tw/co</code> correlation is not statistically significant at the <code>p=.05</code> level.</p>
<p>We also notice from the results that the pair <code>tw/co</code> has a statistically significant Spearman, but not Pearson, correlation. Let’s try to graph it to get some intuition.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">plt.plot(comments,tweets,<span class="string">'ro'</span>,alpha=<span class="number">.3</span>)</div><div class="line">plt.xlabel(<span class="string">'tweets'</span>)</div><div class="line">plt.ylabel(<span class="string">'comments'</span>)</div><div class="line">plt.grid(<span class="string">'on'</span>);</div></pre></td></tr></table></figure>
<p><img src="output_9_0.png" alt="png"></p>
<p>Pearson was not able to see the linear regression because the data is spread out.</p>
<p>Now, for each word, let’s determine whether its number counts in the thirty articles have a statistically significant correlation (again at the less than <code>p =.05</code> level) with each of the three count lists, using the two types of correlation. We’ll just print a list of words, giving the value of the Pearson or Spearman correlation, or both, if statistically significant.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">testwords = [<span class="string">'about'</span>, <span class="string">'are'</span>, <span class="string">'been'</span>, <span class="string">'bush'</span>, <span class="string">'candidate'</span>, <span class="string">'cruz'</span>, <span class="string">'hampshire'</span>, <span class="string">'has'</span>,</div><div class="line">             <span class="string">'have'</span>, <span class="string">'her'</span>, <span class="string">'new'</span>, <span class="string">'obama'</span>, <span class="string">'out'</span>, <span class="string">'party'</span>, <span class="string">'president'</span>, <span class="string">'she'</span>,</div><div class="line">             <span class="string">'state'</span>, <span class="string">'the'</span>, <span class="string">'this'</span>, <span class="string">'was'</span>, <span class="string">'were'</span>, <span class="string">'which'</span>, <span class="string">'will'</span>, <span class="string">'win'</span>]</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ptexts=[open(<span class="string">'data/p&#123;&#125;.txt'</span>.format(i)).read() <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">30</span>)]</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> re</div><div class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</div><div class="line"></div><div class="line">wordcounter = [Counter(re.findall(<span class="string">'[a-z]+'</span>, ptexts[i].lower())) <span class="keyword">for</span> i <span class="keyword">in</span> range(len(ptexts))]</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">w_test</span><span class="params">(w)</span>:</span></div><div class="line">    counts=[c[w] <span class="keyword">for</span> c <span class="keyword">in</span> wordcounter]</div><div class="line">    <span class="keyword">for</span> clist,lab <span class="keyword">in</span> zip((fblikes,tweets,comments),(<span class="string">'fb'</span>,<span class="string">'tw'</span>,<span class="string">'co'</span>)):</div><div class="line">        r,p=pearsonr(counts,clist)</div><div class="line">        <span class="keyword">if</span> p&lt;<span class="number">.05</span>: print(<span class="string">'&#123;&#125;/&#123;&#125; Pearson  r=&#123;:.2f&#125;, p=&#123;:.6f&#125;'</span>.format(w,lab,r,p))</div><div class="line">        r,p=spearmanr(counts,clist)</div><div class="line">        <span class="keyword">if</span> p&lt;<span class="number">.05</span>: print(<span class="string">'&#123;&#125;/&#123;&#125; Spearman r=&#123;:.2f&#125;, p=&#123;:.6f&#125;'</span>.format(w,lab,r,p))</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> w <span class="keyword">in</span> testwords: w_test(w)</div></pre></td></tr></table></figure>
<pre><code>about/fb Pearson  r=0.37, p=0.043212
about/fb Spearman r=0.40, p=0.030467
about/tw Pearson  r=0.54, p=0.002213
about/tw Spearman r=0.52, p=0.003306
are/tw Spearman r=-0.39, p=0.034086
been/fb Spearman r=-0.40, p=0.030489
been/tw Spearman r=-0.37, p=0.042871
bush/fb Spearman r=-0.36, p=0.048523
bush/co Spearman r=-0.38, p=0.037912
candidate/fb Spearman r=-0.51, p=0.004016
candidate/tw Pearson  r=-0.36, p=0.049033
candidate/tw Spearman r=-0.46, p=0.009707
cruz/tw Pearson  r=0.46, p=0.011164
hampshire/fb Pearson  r=-0.38, p=0.038373
hampshire/fb Spearman r=-0.58, p=0.000763
hampshire/tw Pearson  r=-0.41, p=0.025318
hampshire/tw Spearman r=-0.65, p=0.000108
has/fb Spearman r=-0.37, p=0.045807
have/co Spearman r=0.45, p=0.012104
her/co Pearson  r=0.51, p=0.003629
new/fb Pearson  r=-0.40, p=0.028577
new/fb Spearman r=-0.60, p=0.000492
new/tw Pearson  r=-0.47, p=0.009203
new/tw Spearman r=-0.72, p=0.000007
obama/co Pearson  r=0.41, p=0.023994
out/fb Spearman r=-0.39, p=0.034711
party/tw Pearson  r=-0.40, p=0.030355
president/fb Pearson  r=0.47, p=0.008472
president/co Pearson  r=0.39, p=0.031265
she/co Pearson  r=0.63, p=0.000165
state/tw Spearman r=-0.48, p=0.006972
the/tw Pearson  r=0.38, p=0.038402
the/tw Spearman r=0.39, p=0.033835
this/fb Pearson  r=0.44, p=0.015278
this/fb Spearman r=0.60, p=0.000431
this/tw Pearson  r=0.43, p=0.018816
this/tw Spearman r=0.60, p=0.000416
this/co Spearman r=0.45, p=0.011906
was/fb Pearson  r=0.40, p=0.027266
was/fb Spearman r=0.40, p=0.029785
were/tw Spearman r=0.42, p=0.020235
which/tw Pearson  r=0.46, p=0.010975
will/fb Spearman r=-0.39, p=0.031619
win/fb Pearson  r=-0.38, p=0.037361
win/fb Spearman r=-0.56, p=0.001195
win/tw Spearman r=-0.44, p=0.014782
</code></pre><h3 id="Find-most-correlated-words"><a href="#Find-most-correlated-words" class="headerlink" title="Find most correlated words"></a>Find most correlated words</h3><p>Lastly, we will find words from the above tests that have the most positive and most negative Pearson correlations between number counts and each of the three lists.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">plist=&#123;<span class="string">'fb'</span>:[],<span class="string">'tw'</span>:[],<span class="string">'co'</span>:[]&#125;</div><div class="line"><span class="keyword">for</span> w <span class="keyword">in</span> testwords:</div><div class="line">    counts=[c[w] <span class="keyword">for</span> c <span class="keyword">in</span> wordcounter]</div><div class="line">    <span class="keyword">for</span> clist,lab <span class="keyword">in</span> zip((fblikes,tweets,comments),(<span class="string">'fb'</span>,<span class="string">'tw'</span>,<span class="string">'co'</span>)):</div><div class="line">        r,p=pearsonr(counts,clist)</div><div class="line">        <span class="keyword">if</span> p&lt;<span class="number">.05</span>: plist[lab].append((w,r,p))</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> m <span class="keyword">in</span> max,min:</div><div class="line">   <span class="keyword">for</span> lab <span class="keyword">in</span> (<span class="string">'fb'</span>,<span class="string">'tw'</span>,<span class="string">'co'</span>):</div><div class="line">       print(lab,m(plist[lab],key=<span class="keyword">lambda</span> x:x[<span class="number">1</span>]))</div><div class="line">   print()</div></pre></td></tr></table></figure>
<pre><code>fb (&apos;president&apos;, 0.47188160505044835, 0.0084721575440603516)
tw (&apos;about&apos;, 0.53706047291383308, 0.0022125814879941463)
co (&apos;she&apos;, 0.63480048053090932, 0.00016457778749341651)

fb (&apos;new&apos;, -0.39985352242322153, 0.02857665659532841)
tw (&apos;new&apos;, -0.46742494363223464, 0.0092029490096462545)
co (&apos;president&apos;, 0.39389143259482368, 0.031264888900746315)
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">view</span><span class="params">(w,clist,ylab=<span class="string">''</span>)</span>:</span></div><div class="line">    counts=[c[w] <span class="keyword">for</span> c <span class="keyword">in</span> wordcounter]</div><div class="line">    plt.plot(counts,clist,<span class="string">'o'</span>,alpha=<span class="number">.33</span>)</div><div class="line">    lr=linregress(counts,clist)</div><div class="line">    xr=np.arange(max(counts)+<span class="number">1</span>)</div><div class="line">    plt.plot(xr,lr[<span class="number">0</span>]*xr+lr[<span class="number">1</span>],label=<span class="string">'slope=&#123;:.2f&#125;'</span>.format(lr[<span class="number">0</span>]))</div><div class="line">    plt.xlabel(<span class="string">'#occurrences of word "&#123;&#125;"'</span>.format(w))</div><div class="line">    plt.title(<span class="string">'slope=&#123;:.2f&#125;'</span>.format(lr[<span class="number">0</span>]))</div><div class="line">    plt.ylabel(ylab)</div><div class="line">    plt.xlim(<span class="number">-.5</span>,max(counts)+<span class="number">.5</span>)</div><div class="line">    plt.ylim(<span class="number">-.05</span>*max(clist),<span class="number">1.05</span>*max(clist))</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">i=<span class="number">0</span></div><div class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">7</span>))</div><div class="line"><span class="keyword">for</span> w,clist,lab <span class="keyword">in</span> zip((<span class="string">'president'</span>,<span class="string">'about'</span>,<span class="string">'she'</span>),(fblikes,tweets,comments),(<span class="string">'fb'</span>,<span class="string">'tw'</span>,<span class="string">'co'</span>)):</div><div class="line">    i+=<span class="number">1</span></div><div class="line">    plt.subplot(<span class="number">2</span>,<span class="number">3</span>,i)</div><div class="line">    view(w,clist,lab)</div><div class="line"><span class="keyword">for</span> w,clist,lab <span class="keyword">in</span> zip((<span class="string">'new'</span>,<span class="string">'new'</span>,<span class="string">'president'</span>),(fblikes,tweets,comments),(<span class="string">'fb'</span>,<span class="string">'tw'</span>,<span class="string">'co'</span>)):</div><div class="line">    i+=<span class="number">1</span></div><div class="line">    plt.subplot(<span class="number">2</span>,<span class="number">3</span>,i)</div><div class="line">    view(w,clist,lab)</div><div class="line">plt.tight_layout()</div></pre></td></tr></table></figure>
<p><img src="output_22_0.png" alt="png"></p>
</div></article><div class="tags"><a href="/tags/Machine-Learning/">Machine Learning</a><a href="/tags/Python/">Python</a><a href="/tags/Spearman-Correlation/">Spearman Correlation</a><a href="/tags/Pearson-Correlation/">Pearson Correlation</a><a href="/tags/Linear-Regression/">Linear Regression</a></div><div class="paginator"><a href="/2016/05/04/Logistic-Regression/" class="next"><span>Suivant</span><i class="iconfont icon-right"></i></a></div><section id="comments"><div id="disqus_thread"></div></section><script type="text/javascript">var disqus_config = function () {
    this.page.url = 'http://.alexsinfarosa.com/2016/05/08/Spearman-and-Pearson-Correlation/';
    this.page.identifier = '2016/05/08/Spearman-and-Pearson-Correlation/';
    this.page.title = 'Spearman and Pearson Correlation';
};
(function() {
var d = document, s = d.createElement('script');

s.src = '//alexsinfarosa-com.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();</script></section><footer><div class="copyright"><p class="power">Powered by <a href="https://hexo.io/">Hexo</a> and Theme by <a href="https://github.com/ahonn/hexo-theme-even"> Even</a></p><p class="since">&copy;2016<span class="heart"><i class="iconfont icon-heart"></i></span><span class="author">Alex Sinfarosa</span></p></div><label id="back2top"><i class="iconfont icon-up"></i></label></footer></div><script src="/js/zepto.min.js"></script><script src="/js/theme.js"></script><!-- hexo-inject:begin --><!-- hexo-inject:end --></body></html>